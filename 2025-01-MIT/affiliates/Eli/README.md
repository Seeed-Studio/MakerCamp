# Shenzhen: Hardware Stories 

This remarkable city touches our lives in remarkable ways. The computer that I am writing this on was assembled in Shenzhen. My mouse has the words 'Made in Shenzhen' printed in tiny text above the charge port. The ubiquity of objects made here and sent abroad is staggering.

As a hardware nerd growing up watching shows like How It's Made and MythBusters and now a professional in the open-source hardware space, Shenzhen has always been at the top of my list. This is why after seeing Cedric Honnet present his research and describe the ScalableHCI symposium at the Open Hardware Summit in 2024, I had a clear goal: to be a part of this community of hackers, makers, and researchers exploring and experiencing the city. Achieving this goal would be no small feat. Purchasing flights, mix-ups with visa applications, leaving my community in Providence, RI, taking time off work all tried to hold me home. But the support of my community, the help of my friends, the encouragement from Cedric, and the generosity of my boss all coalesced just in time for this trip to happen. Thank you to all who helped make this trip happen! 

# Hackathon
![Screenshot_from_2025-09-01_09-55-00](https://github.com/user-attachments/assets/84ed1703-f636-4a86-a026-ea8871b20718)

Our team's hackathon project, "Little Brother," was an exciting and challenging endeavor into the realm of smart spaces. The project is an AI-powered camera system mounted on a room-scale, cable-driven gantry robotâ€”essentially a Skycam for your workshop.

![Screenshot_from_2025-09-01_09-53-55](https://github.com/user-attachments/assets/fbe43e7e-ef6c-433d-84b4-9a450baf9876)

We aimed to create a helpful companion that could assist with various tasks, from locating misplaced items to documenting your work. The system uses a Raspberry Pi 5, a webcam for object detection, and a projector to highlight the identified objects. A system of cables, pulleys, and motors allows "Little Brother" to navigate the workspace.

![Screenshot_from_2025-09-01_09-55-48](https://github.com/user-attachments/assets/54efd256-f962-475e-918f-cdb146677515)

During the hackathon, we developed a natural language understanding (NLU) core that translates spoken commands, like "Where's the cell phone?", into actions for the robot. The system then locates the requested object and shines a light on it with the projector.

![Screenshot_from_2025-09-01_10-12-43](https://github.com/user-attachments/assets/fdf0376b-4b63-40eb-a95e-f0031c7fa24f)

We demonstrated "Little Brother's" ability to find various items on a desk, even when they were moved or partially obscured. Our project was awarded the "Smart Making Space Award".

![Screenshot_from_2025-09-01_10-10-04](https://github.com/user-attachments/assets/064bbeae-7e3b-464f-9f62-974b9b07b4d2)

![Screenshot_from_2025-09-01_10-11-46](https://github.com/user-attachments/assets/c3404351-0491-4a72-9728-237f60c484ec)

![Screenshot_from_2025-09-01_10-13-58](https://github.com/user-attachments/assets/4a91a8c2-2e9b-4f2f-b10d-ae46ebdc671a)

[Video](https://youtu.be/nWw6RP7YdS4)



